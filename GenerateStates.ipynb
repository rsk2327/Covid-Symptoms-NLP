{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords \n",
    "\n",
    "from transformers import BertForSequenceClassification, BertTokenizer, BertForMaskedLM\n",
    "\n",
    "from simpletransformers.language_modeling import LanguageModelingModel\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity, paired_euclidean_distances\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.preprocessing import normalize, StandardScaler, MinMaxScaler\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from functools import partial\n",
    "\n",
    "import pickle\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "\n",
    "# from utils import *\n",
    "# from plotting import *\n",
    "\n",
    "import time\n",
    "\n",
    "import feather\n",
    "\n",
    "import _pickle as cPickle\n",
    "\n",
    "import json\n",
    "import codecs\n",
    "import marshal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputFolder = '/data1/roshansk/ADRModel_DataStore/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "covidData = '/data1/roshansk/covid_data/'\n",
    "os.listdir(covidData)\n",
    "\n",
    "df = pd.read_csv(os.path.join(covidData, 'messages_cm_mar1_apr23_noRT.csv'), nrows = 300000)\n",
    "\n",
    "df = df[['message_id','user_id','message']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('/data1/roshansk/Exp1/checkpoint-141753-epoch-1')\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained('/data1/roshansk/Exp1/checkpoint-141753-epoch-1', output_hidden_states= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating individual files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:15<00:00,  6.33it/s]\n"
     ]
    }
   ],
   "source": [
    "outputFolder = '/data1/roshansk/ADRModel_DataStore/'\n",
    "embeddingType = 'last4sum'\n",
    "\n",
    "for i in tqdm(range(150000,150100)):\n",
    "            \n",
    "    if os.path.exists(os.path.join(outputFolder, f\"{i}.msh\")):\n",
    "        continue\n",
    "\n",
    "\n",
    "    tokens = tokenizer.encode(df.iloc[i]['message'].lower())\n",
    "    decoded = tokenizer.decode(tokens).split(\" \")\n",
    "    logits, hidden_states = model(torch.Tensor(tokens).unsqueeze(0).long())\n",
    "\n",
    "    hidden_states = torch.stack(hidden_states).squeeze(1).permute(1,0,2)\n",
    "\n",
    "\n",
    "    if embeddingType == 'last4sum':\n",
    "        embedding = torch.sum(hidden_states[:,9:13,:],1)\n",
    "    elif embeddingType =='last4concat':\n",
    "        embedding = hidden_states[tokenIndex,9:13,:].reshape(-1)\n",
    "    elif embeddingType == 'secondlast':\n",
    "        embedding = hidden_states[tokenIndex,-2,:]\n",
    "    else:\n",
    "        embedding = hidden_states[tokenIndex,-1,:]\n",
    "\n",
    "\n",
    "    embedding = embedding.detach().cpu().numpy()\n",
    "\n",
    "    marshal.dump(embedding.tolist(), open(os.path.join(outputFolder, f\"{i}.msh\"), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Agg files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggFiles(index, numComp, df, tokenizer, inputFolder, outputFolder):\n",
    "\n",
    "    IDList = []\n",
    "    tokenList = []\n",
    "    embList = []\n",
    "\n",
    "    for i in tqdm(range(index*numComp, (index+1)*numComp)):\n",
    "        text = df.iloc[i]['message']\n",
    "\n",
    "        tokens = tokenizer.convert_ids_to_tokens(tokenizer.encode(text))\n",
    "\n",
    "\n",
    "        emb = np.array(marshal.load(open(os.path.join(inputFolder, f\"{i}.msh\"),'rb' )))\n",
    "\n",
    "        IDList += [i]*len(tokens)\n",
    "        tokenList += tokens\n",
    "\n",
    "        embList.append(emb)\n",
    "\n",
    "    IDList = np.array(IDList)\n",
    "    tokenList = np.array(tokenList)\n",
    "    embList = np.concatenate(embList,axis=0)\n",
    "\n",
    "    subDict = {'id':IDList, 'token':tokenList,'emb':embList}\n",
    "\n",
    "\n",
    "    \n",
    "    filename = os.path.join(outputFolder, f\"{index}.pkl\")\n",
    "    pickle.dump(subDict, open(filename,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggFiles(1, numComp, df, tokenizer, inputFolder, outputFolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['89999.pkl',\n",
       " '119999.pkl',\n",
       " '9999.pkl',\n",
       " '59999.pkl',\n",
       " '149999.pkl',\n",
       " '99999.pkl',\n",
       " '139999.pkl',\n",
       " '39999.pkl',\n",
       " '49999.pkl',\n",
       " '129999.pkl',\n",
       " '29999.pkl',\n",
       " '19999.pkl',\n",
       " '109999.pkl',\n",
       " '79999.pkl',\n",
       " '69999.pkl']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('/data1/roshansk/ADRModel_DataStore_10000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [02:48<00:00, 59.45it/s]\n",
      "100%|██████████| 10000/10000 [02:53<00:00, 57.60it/s]\n",
      "100%|██████████| 10000/10000 [03:13<00:00, 51.69it/s]\n",
      "100%|██████████| 10000/10000 [02:57<00:00, 56.49it/s]\n",
      "100%|██████████| 10000/10000 [03:16<00:00, 50.90it/s]\n",
      "100%|██████████| 10000/10000 [03:24<00:00, 48.82it/s]\n",
      "100%|██████████| 10000/10000 [03:17<00:00, 50.68it/s]\n",
      "100%|██████████| 10000/10000 [03:14<00:00, 51.38it/s]\n",
      "100%|██████████| 10000/10000 [03:13<00:00, 51.61it/s]\n",
      "100%|██████████| 10000/10000 [03:20<00:00, 49.91it/s] \n",
      "100%|██████████| 10000/10000 [03:07<00:00, 53.37it/s] \n",
      "100%|██████████| 10000/10000 [02:53<00:00, 57.70it/s]\n",
      "100%|██████████| 10000/10000 [02:43<00:00, 60.99it/s]\n",
      "100%|██████████| 10000/10000 [02:46<00:00, 60.03it/s]\n",
      "100%|██████████| 10000/10000 [04:30<00:00, 36.97it/s]\n"
     ]
    }
   ],
   "source": [
    "numComp = 10000\n",
    "outputFolder = '/data1/roshansk/ADRModel_DataStore_10000'\n",
    "inputFolder = '/data1/roshansk/ADRModel_DataStore/'\n",
    "\n",
    "for i in range(0,15):\n",
    "    \n",
    "    aggFiles(i, numComp, df, tokenizer, inputFolder, outputFolder)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
